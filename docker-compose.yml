services:
  chatbot-backend:
    build: .
    container_name: chatbot
    ports:
      - "${PORT}:5001"
    volumes:
      - "./${PUBLIC_FOLDER}:/app/${PUBLIC_FOLDER}"
    env_file:
      - .env
    restart: unless-stopped
    depends_on:
      - ollama
      - chroma

  chroma:
    image: chromadb/chroma:latest
    container_name: chroma
    ports:
      - "8000:8000"
    environment:
      CHROMA_SERVER_HTTP_PORT: 8000
    volumes:
      - ./chroma:/chroma/chroma
    restart: unless-stopped

  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    ports:
      - "${OLLAMA_PORT}:11434" # Ollama default port
    restart: always
    volumes:
      - "./ollama_data:/ollama_data" # persistent data
    environment:
      - OLLAMA_MODEL=${OLLAMA_MODEL}
      - OLLAMA_BASE_URL=${OLLAMA_BASE_URL}
      - OLLAMA_PORT=${OLLAMA_PORT}

  open-webui:
    image: ghcr.io/open-webui/open-webui:main
    container_name: open-webui
    ports:
      - "3000:8080"
    volumes:
      - open-webui-data:/app/backend/data
    environment:
      - OLLAMA_BASE_URL=http://ollama:11434 # connect to the Ollama container
      - WEBUI_AUTH=False # disable login (optional)
    depends_on:
      - ollama
    restart: unless-stopped

volumes:
  ollama_data:
    name: ollama_data
  chroma_data:
    name: chroma_data
  open-webui-data:
    name: open-webui-data
